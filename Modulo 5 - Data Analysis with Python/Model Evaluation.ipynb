{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bb85b0",
   "metadata": {},
   "source": [
    "# MODULE 5 - Model Evaluation\n",
    " Ejercicios realizados por: Denisse Maria Ramirez Colmenero A01561497 \n",
    " \n",
    " \n",
    " **Subtema: Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af4f7f",
   "metadata": {},
   "source": [
    "Separar nuestro conjunto de datos en entrenamiento y prueba y utilizar el de prueba para tener una idea de como se comporta nuestro modelo en el mundo real (masomenos entre 70% entrenamiento y 30% prueba). \n",
    "El conjunto de entrenamiento se usaría para construir el modelo y encontrar posibles relaciones que nos ayuden a predecir. \n",
    "Despues el conjunto de prueba lo usamos para medir el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0)\n",
    "\n",
    "#x_data y y_data son las variables independientes y dependientes respectivamente\n",
    "#test_size: el porcentaje de la partición "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ababc",
   "metadata": {},
   "source": [
    "GENERALIZATION ERROR \n",
    "Es una medida de la eficacia de nuestros datos en la predicción de datos no vistos anteriormente.\n",
    "El error que obtenemos utilizando nuestros datos de prueba es una aproximación a este error.\n",
    "\n",
    "Si usamos mucho porcentaje del conjunto de datos para entrenamiento, el resultado de la predicción va a ser bueno, pero la precisión va a ser baja, ya que cada vez que entrenemos el modelo con distinto de combinación de muestras, siempre el generalization error va a ser cercano, pero entre ellos, van a estar uno muy lejos del otro. Lo contrario pasaría si utilizamos muy poco porcentaje para entrenar. \n",
    "\n",
    "\"all our error estimates are relatively close together,but they are further away from the true generalization performance.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312bf4f",
   "metadata": {},
   "source": [
    "Para hacer frente a este problema usamos: Cross-Validation\n",
    "    \n",
    "El conjunto de datos se parte en K folds, a cada uno le toca ser de entrenamiento y de prueba. Hasta que todos los K folds hayan sido entrenamiento y prueba, se obtiene el promedio de los errores de cada ronda. \n",
    "\n",
    "Pueden ser distintas metricas de error: R2-squared, MAE, RMSE, MAPE, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np \n",
    "\n",
    "scores = cross_val_score(lr, x_data, y_data, cv=3) #lr=Linear Regression, returns an array of scores \n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict() #si queremos saber los valores reales predichos antes de que arroje el resultado del error "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
